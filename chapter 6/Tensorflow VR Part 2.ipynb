{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Visual Recognition Sample Application Part 2\n",
    "\n",
    "## Provide a User Interface with a PixieApp\n",
    "\n",
    "## Define the model metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dtaieb/anaconda/envs/dashboard/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.5\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import requests\n",
    "models = {\n",
    "    \"mobilenet\": {\n",
    "        \"base_url\":\"https://github.com/DTAIEB/Thoughtful-Data-Science/raw/master/chapter%206/Visual%20Recognition/mobilenet_v1_0.50_224\",\n",
    "        \"model_file_url\": \"frozen_graph.pb\",\n",
    "        \"label_file\": \"labels.txt\",\n",
    "        \"output_layer\": \"MobilenetV1/Predictions/Softmax\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# helper method for reading attributes from the model metadata\n",
    "def get_model_attribute(model, key, default_value = None):\n",
    "    if key not in model:\n",
    "        if default_value is None:\n",
    "            raise Exception(\"Require model attribute {} not found\".format(key))\n",
    "        return default_value\n",
    "    return model[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper methods for loading the graph and labels for a given model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper method for resolving url relative to the selected model\n",
    "def get_url(model, path):\n",
    "    return model[\"base_url\"] + \"/\" + path\n",
    "    \n",
    "# Download the serialized model and create a TensorFlow graph\n",
    "def load_graph(model):\n",
    "    graph = tf.Graph()\n",
    "    graph_def = tf.GraphDef()\n",
    "    graph_def.ParseFromString(\n",
    "        requests.get( get_url( model, model[\"model_file_url\"] ) ).content\n",
    "    )\n",
    "    with graph.as_default():\n",
    "        tf.import_graph_def(graph_def)\n",
    "    return graph\n",
    "\n",
    "# Load the labels\n",
    "def load_labels(model, as_json = False):\n",
    "    labels = [line.rstrip() \\\n",
    "        for line in requests.get( get_url( model, model[\"label_file\"] ) ).text.split(\"\\n\") \\\n",
    "        if line != \"\"]\n",
    "    if as_json:\n",
    "        return [{\"index\": item.split(\":\")[0], \"label\" : item.split(\":\")[1]} for item in labels]\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use BeautifulSoup to scrape the images from a given url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as BS\n",
    "import re\n",
    "\n",
    "# return an array of all the images scraped from an html page\n",
    "def get_image_urls(url):\n",
    "    # Instantiate a BeautifulSoup parser\n",
    "    soup = BS(requests.get(url).text, \"html.parser\")\n",
    "    \n",
    "    # Local helper method for extracting url\n",
    "    def extract_url(val):\n",
    "        m = re.match(r\"url\\((.*)\\)\", val)\n",
    "        val = m.group(1) if m is not None else val\n",
    "        return \"http:\" + val if val.startswith(\"//\") else val\n",
    "    \n",
    "    # List comprehension that look for <img> elements and backgroud-image styles\n",
    "    return [extract_url(imgtag['src']) for imgtag in soup.find_all('img')] + [ \\\n",
    "        extract_url(val.strip()) for key,val in \\\n",
    "        [tuple(selector.split(\":\")) for elt in soup.select(\"[style]\") \\\n",
    "            for selector in elt[\"style\"].strip(\" ;\").split(\";\")] \\\n",
    "            if key.strip().lower()=='background-image' \\\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper method for downloading an image into a temp file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "def download_image(url):\n",
    "    response = requests.get(url, stream=True)\n",
    "    if response.status_code == 200:\n",
    "        with tempfile.NamedTemporaryFile(delete=False) as f:\n",
    "            for chunk in response.iter_content(2048):\n",
    "                f.write(chunk)\n",
    "            return f.name\n",
    "    else:\n",
    "        raise Exception(\"Unable to download image: {}\".format(response.status_code))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decode an image into a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decode a given image into a tensor\n",
    "def read_tensor_from_image_file(model, file_name):\n",
    "    file_reader = tf.read_file(file_name, \"file_reader\")\n",
    "    if file_name.endswith(\".png\"):\n",
    "        image_reader = tf.image.decode_png(file_reader, channels = 3,name='png_reader')\n",
    "    elif file_name.endswith(\".gif\"):\n",
    "        image_reader = tf.squeeze(tf.image.decode_gif(file_reader,name='gif_reader'))\n",
    "    elif file_name.endswith(\".bmp\"):\n",
    "        image_reader = tf.image.decode_bmp(file_reader, name='bmp_reader')\n",
    "    else:\n",
    "        image_reader = tf.image.decode_jpeg(file_reader, channels = 3, name='jpeg_reader')\n",
    "    float_caster = tf.cast(image_reader, tf.float32)\n",
    "    dims_expander = tf.expand_dims(float_caster, 0);\n",
    "    \n",
    "    # Read some info from the model metadata, providing default values\n",
    "    input_height = get_model_attribute(model, \"input_height\", 224)\n",
    "    input_width = get_model_attribute(model, \"input_width\", 224)\n",
    "    input_mean = get_model_attribute(model, \"input_mean\", 0)\n",
    "    input_std = get_model_attribute(model, \"input_std\", 255)\n",
    "        \n",
    "    resized = tf.image.resize_bilinear(dims_expander, [input_height, input_width])\n",
    "    normalized = tf.divide(tf.subtract(resized, [input_mean]), [input_std])\n",
    "    sess = tf.Session()\n",
    "    result = sess.run(normalized)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score_image method that run the model and return the top 5 candidate answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# classify an image given its url\n",
    "def score_image(graph, model, url):\n",
    "    # Get the input and output layer from the model\n",
    "    input_layer = get_model_attribute(model, \"input_layer\", \"input\")\n",
    "    output_layer = get_model_attribute(model, \"output_layer\")\n",
    "    \n",
    "    # Download the image and build a tensor from its data\n",
    "    t = read_tensor_from_image_file(model, download_image(url))\n",
    "    \n",
    "    # Retrieve the tensors corresponding to the input and output layers\n",
    "    input_tensor = graph.get_tensor_by_name(\"import/\" + input_layer + \":0\");\n",
    "    output_tensor = graph.get_tensor_by_name(\"import/\" + output_layer + \":0\");\n",
    "\n",
    "    with tf.Session(graph=graph) as sess:\n",
    "        # Execute the output, overriding the input tensor with the one corresponding\n",
    "        # to the image in the feed_dict argument\n",
    "        results = sess.run(output_tensor, {input_tensor: t})\n",
    "    results = np.squeeze(results)\n",
    "    # select the top 5 candidate and match them to the labels\n",
    "    top_k = results.argsort()[-5:][::-1]\n",
    "    labels = load_labels(model)\n",
    "    return [(labels[i].split(\":\")[1], results[i]) for i in top_k]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PixieApp with the following screens:\n",
    "1. Ask the user for a url to a web page\n",
    "2. Display the images with top 5 candidate classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">.pd_warning{display:none;}</style><div class=\"pd_warning\"><em>Hey, there's something awesome here! To see it, open this notebook outside GitHub, in a viewer like Jupyter</em></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "pixieapp_metadata": null
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pixiedust.display.app import *\n",
    "\n",
    "@PixieApp\n",
    "class ScoreImageApp():\n",
    "    def setup(self):\n",
    "        self.model = models[\"mobilenet\"]\n",
    "        self.graph = load_graph( self.model )\n",
    "\n",
    "    @route()\n",
    "    def main_screen(self):\n",
    "        return \"\"\"\n",
    "<style>\n",
    "    div.outer-wrapper {\n",
    "        display: table;width:100%;height:300px;\n",
    "    }\n",
    "    div.inner-wrapper {\n",
    "        display: table-cell;vertical-align: middle;height: 100%;width: 100%;\n",
    "    }\n",
    "</style>\n",
    "<div class=\"outer-wrapper\">\n",
    "    <div class=\"inner-wrapper\">\n",
    "        <div class=\"col-sm-3\"></div>\n",
    "        <div class=\"input-group col-sm-6\">\n",
    "          <input id=\"url{{prefix}}\" type=\"text\" class=\"form-control\"\n",
    "              value=\"https://www.flickr.com/search/?text=cats\"\n",
    "              placeholder=\"Enter a url that contains images\">\n",
    "          <span class=\"input-group-btn\">\n",
    "            <button class=\"btn btn-default\" type=\"button\" pd_options=\"image_url=$val(url{{prefix}})\">Go</button>\n",
    "          </span>\n",
    "        </div>\n",
    "    </div>\n",
    "</div>        \n",
    "\"\"\"\n",
    "    \n",
    "    @route(image_url=\"*\")\n",
    "    @templateArgs\n",
    "    def do_process_url(self, image_url):\n",
    "        image_urls = get_image_urls(image_url)\n",
    "        return \"\"\"\n",
    "<div>\n",
    "{%for url in image_urls%}\n",
    "<div style=\"float: left; font-size: 9pt; text-align: center; width: 30%; margin-right: 1%; margin-bottom: 0.5em;\">\n",
    "<img src=\"{{url}}\" style=\"width: 100%\">\n",
    "<div style=\"display:inline-block\" pd_render_onload pd_options=\"score_url={{url}}\"></div>\n",
    "</div>\n",
    "{%endfor%}\n",
    "<p style=\"clear: both;\">\n",
    "</div>\n",
    "        \"\"\"\n",
    "    \n",
    "    @route(score_url=\"*\")\n",
    "    @templateArgs\n",
    "    def do_score_url(self, score_url):\n",
    "        results = score_image(self.graph, self.model, score_url)\n",
    "        return \"\"\"\n",
    "<ul style=\"text-align:left\">\n",
    "{%for label, confidence in results%}\n",
    "<li><b>{{label}}</b>: {{confidence}}</li>\n",
    "{%endfor%}\n",
    "</ul>\n",
    "\"\"\"\n",
    "    \n",
    "app = ScoreImageApp()\n",
    "app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
