{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Visual Recognition Sample Application Part 4\n",
    "\n",
    "## Tranfer Learning: Re-train MobileNet models with custom images\n",
    "\n",
    "## Define the model metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import requests\n",
    "models = {\n",
    "    \"mobilenet\": {\n",
    "        \"base_url\":\"https://github.com/DTAIEB/Thoughtful-Data-Science/raw/master/chapter%206/Visual%20Recognition/mobilenet_v1_0.50_224\",\n",
    "        \"model_file_url\": \"frozen_graph.pb\",\n",
    "        \"label_file\": \"labels.txt\",\n",
    "        \"output_layer\": \"MobilenetV1/Predictions/Softmax\",\n",
    "        \"bottleneck_tensor_name\": 'import/MobilenetV1/Predictions/Reshape:0',\n",
    "        \"resized_input_tensor_name\": 'import/input:0',\n",
    "        \"input_width\": 224,\n",
    "        \"input_height\": 224,\n",
    "        \"input_depth\": 3,\n",
    "        \"bottleneck_tensor_size\": 1001        \n",
    "    }\n",
    "}\n",
    "\n",
    "# helper method for reading attributes from the model metadata\n",
    "def get_model_attribute(model, key, default_value = None):\n",
    "    if key not in model:\n",
    "        if default_value is None:\n",
    "            raise Exception(\"Require model attribute {} not found\".format(key))\n",
    "        return default_value\n",
    "    return model[key]\n",
    "\n",
    "def ensure_dir_exists(dir_name):\n",
    "    if not os.path.exists(dir_name):\n",
    "        os.makedirs(dir_name)\n",
    "    return dir_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper methods for loading the graph and labels for a given model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper method for resolving url relative to the selected model\n",
    "def get_url(model, path):\n",
    "    return model[\"base_url\"] + \"/\" + path\n",
    "    \n",
    "# Download the serialized model and create a TensorFlow graph\n",
    "def load_graph(model):\n",
    "    graph = tf.Graph()\n",
    "    graph_def = tf.GraphDef()\n",
    "    graph_def.ParseFromString(\n",
    "        requests.get( get_url( model, model[\"model_file_url\"] ) ).content\n",
    "    )\n",
    "    with graph.as_default():\n",
    "        tf.import_graph_def(graph_def)\n",
    "    return graph\n",
    "\n",
    "# Load the labels\n",
    "def load_labels(model, as_json = False):\n",
    "    labels = [line.rstrip() \\\n",
    "        for line in requests.get( get_url( model, model[\"label_file\"] ) ).text.split(\"\\n\") \\\n",
    "        if line != \"\"]\n",
    "    if as_json:\n",
    "        return [{\"index\": item.split(\":\")[0], \"label\" : item.split(\":\")[1]} for item in labels]\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use BeautifulSoup to scrape the images from a given url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as BS\n",
    "import re\n",
    "\n",
    "# return an array of all the images scraped from an html page\n",
    "def get_image_urls(url):\n",
    "    # Instantiate a BeautifulSoup parser\n",
    "    soup = BS(requests.get(url).text, \"html.parser\")\n",
    "    \n",
    "    # Local helper method for extracting url\n",
    "    def extract_url(val):\n",
    "        m = re.match(r\"url\\((.*)\\)\", val)\n",
    "        val = m.group(1) if m is not None else val\n",
    "        return \"http:\" + val if val.startswith(\"//\") else val\n",
    "    \n",
    "    # List comprehension that look for <img> elements and backgroud-image styles\n",
    "    return [extract_url(imgtag['src']) for imgtag in soup.find_all('img')] + [ \\\n",
    "        extract_url(val.strip()) for key,val in \\\n",
    "        [tuple(selector.split(\":\")) for elt in soup.select(\"[style]\") \\\n",
    "            for selector in elt[\"style\"].strip(\" ;\").split(\";\")] \\\n",
    "            if key.strip().lower()=='background-image' \\\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper method for downloading an image into a temp file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "def download_image(url):\n",
    "    response = requests.get(url, stream=True)\n",
    "    if response.status_code == 200:\n",
    "        with tempfile.NamedTemporaryFile(delete=False) as f:\n",
    "            for chunk in response.iter_content(2048):\n",
    "                f.write(chunk)\n",
    "            return f.name\n",
    "    else:\n",
    "        raise Exception(\"Unable to download image: {}\".format(response.status_code))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decode an image into a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decode a given image into a tensor\n",
    "def read_tensor_from_image_file(model, file_name):\n",
    "    file_reader = tf.read_file(file_name, \"file_reader\")\n",
    "    if file_name.endswith(\".png\"):\n",
    "        image_reader = tf.image.decode_png(file_reader, channels = 3,name='png_reader')\n",
    "    elif file_name.endswith(\".gif\"):\n",
    "        image_reader = tf.squeeze(tf.image.decode_gif(file_reader,name='gif_reader'))\n",
    "    elif file_name.endswith(\".bmp\"):\n",
    "        image_reader = tf.image.decode_bmp(file_reader, name='bmp_reader')\n",
    "    else:\n",
    "        image_reader = tf.image.decode_jpeg(file_reader, channels = 3, name='jpeg_reader')\n",
    "    float_caster = tf.cast(image_reader, tf.float32)\n",
    "    dims_expander = tf.expand_dims(float_caster, 0);\n",
    "    \n",
    "    # Read some info from the model metadata, providing default values\n",
    "    input_height = get_model_attribute(model, \"input_height\", 224)\n",
    "    input_width = get_model_attribute(model, \"input_width\", 224)\n",
    "    input_mean = get_model_attribute(model, \"input_mean\", 0)\n",
    "    input_std = get_model_attribute(model, \"input_std\", 255)\n",
    "        \n",
    "    resized = tf.image.resize_bilinear(dims_expander, [input_height, input_width])\n",
    "    normalized = tf.divide(tf.subtract(resized, [input_mean]), [input_std])\n",
    "    sess = tf.Session()\n",
    "    result = sess.run(normalized)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score_image method that run the model and return a dictionary with the generic and custom model if available. Each entry contains the top 5 candidate answers as value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# classify an image given its url\n",
    "def score_image(graph, model, url):\n",
    "    # Download the image and build a tensor from its data\n",
    "    t = read_tensor_from_image_file(model, download_image(url))\n",
    "    \n",
    "    def do_score_image(graph, output_layer, labels):        \n",
    "        # Retrieve the tensors corresponding to the input and output layers\n",
    "        input_tensor = graph.get_tensor_by_name(\"import/\" + input_layer + \":0\");\n",
    "        output_tensor = graph.get_tensor_by_name( output_layer + \":0\");\n",
    "\n",
    "        with tf.Session(graph=graph) as sess:\n",
    "            # Execute the output, overriding the input tensor with the one corresponding\n",
    "            # to the image in the feed_dict argument\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            results = sess.run(output_tensor, {input_tensor: t})\n",
    "        results = np.squeeze(results)\n",
    "        # select the top 5 candidates and match them to the labels\n",
    "        top_k = results.argsort()[-5:][::-1]\n",
    "        return [(labels[i].split(\":\")[1], results[i]) for i in top_k]\n",
    "    \n",
    "    results = {}\n",
    "    input_layer = get_model_attribute(model, \"input_layer\", \"input\")\n",
    "    labels = load_labels(model)\n",
    "    results[\"mobilenet\"] = do_score_image(graph, \"import/\" + get_model_attribute(model, \"output_layer\"), labels)\n",
    "    if \"custom_graph\" in model and \"custom_labels\" in model:\n",
    "        with open(model[\"custom_labels\"]) as f:\n",
    "            labels = [line.rstrip() for line in f.readlines() if line != \"\"]\n",
    "            custom_labels = [\"{}:{}\".format(i, label) for i,label in zip(range(len(labels)), labels)]\n",
    "        results[\"custom\"] = do_score_image(model[\"custom_graph\"], \"final_result\", custom_labels)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tooling for acquiring the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "wnid_to_urls = pandas.read_csv('/Users/dtaieb/Downloads/fall11_urls.txt', sep='\\t', names=[\"wnid\", \"url\"],\n",
    "                     header=0, error_bad_lines=False, warn_bad_lines=False, encoding=\"ISO-8859-1\")\n",
    "wnid_to_urls['wnid'] = wnid_to_urls['wnid'].apply(lambda x: x.split(\"_\")[0])\n",
    "wnid_to_urls = wnid_to_urls.dropna()\n",
    "\n",
    "wnid_to_words = pandas.read_csv('/Users/dtaieb/Downloads/words.txt', sep='\\t', names=[\"wnid\", \"description\"],\n",
    "                     header=0, error_bad_lines=False, warn_bad_lines=False, encoding=\"ISO-8859-1\")\n",
    "wnid_to_words = wnid_to_words.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_url_for_keywords(keywords):\n",
    "    results = {}\n",
    "    for keyword in keywords:\n",
    "        df = wnid_to_words.loc[wnid_to_words['description'] == keyword]\n",
    "        row_list = df['wnid'].values.tolist()\n",
    "        descriptions = df['description'].values.tolist()\n",
    "        if len(row_list) > 0:\n",
    "            results[descriptions[0]] = wnid_to_urls.loc[wnid_to_urls['wnid'] == row_list[0]][\"url\"].values.tolist()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pixiedust": {
     "displayParams": {
      "handlerId": "barChart",
      "keyFields": "wnid",
      "rendererId": "bokeh",
      "sortby": "Values DESC"
     }
    }
   },
   "outputs": [],
   "source": [
    "import pixiedust\n",
    "display(wnid_to_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pixiedust.utils.environment import Environment\n",
    "import os\n",
    "root_dir = ensure_dir_exists(os.path.join(Environment.pixiedustHome, \"imageRecoApp\"))\n",
    "image_dir = root_dir\n",
    "\n",
    "def download_image_into_dir(url, path):\n",
    "    file_name = url[url.rfind(\"/\")+1:]\n",
    "    if not file_name.endswith(\".jpg\"):\n",
    "        return\n",
    "    file_name = os.path.join(path, file_name)\n",
    "    if os.path.exists(file_name):\n",
    "        print(\"Image already downloaded {}\".format(url))\n",
    "    else:\n",
    "        print(\"Downloading image {}...\".format(url), end='')\n",
    "        try:\n",
    "            response = requests.get(url, stream=True)\n",
    "            if response.status_code == 200:\n",
    "                with open(file_name, 'wb') as f:\n",
    "                    for chunk in response.iter_content(2048):\n",
    "                        f.write(chunk)\n",
    "            else:\n",
    "                print(\"Error: {}\".format(response.status_code))\n",
    "        except Exception as e:\n",
    "            print(\"Error: {}\".format(e))\n",
    "        print(\"done\")\n",
    "\n",
    "image_dict = get_url_for_keywords([\"apple\", \"orange\", \"pear\", \"banana\"])\n",
    "for key in image_dict:\n",
    "    path = ensure_dir_exists(os.path.join(image_dir, key))\n",
    "    count = 0\n",
    "    for url in image_dict[key]:\n",
    "        download_image_into_dir(url, path)\n",
    "        count += 1\n",
    "        if count > 500:\n",
    "            break;\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrain the model using the downloaded images from the previous section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import os.path\n",
    "import hashlib\n",
    "from datetime import datetime\n",
    "from tensorflow.python.framework import graph_util\n",
    "from tensorflow.python.platform import gfile\n",
    "from tensorflow.python.util import compat\n",
    "\n",
    "MAX_NUM_IMAGES_PER_CLASS = 2 ** 27 - 1  # ~134M\n",
    "final_tensor_name = \"final_result\"\n",
    "tmp_root_dir = ensure_dir_exists(os.path.join(root_dir, \"tmp\"))\n",
    "bottleneck_dir = ensure_dir_exists(os.path.join(tmp_root_dir, \"bottleneck\"))\n",
    "architecture=\"mobilenet_0.50_224\"\n",
    "train_batch_size = 100\n",
    "test_batch_size = 1\n",
    "validation_batch_size = 100\n",
    "how_many_training_steps = 500\n",
    "eval_step_interval = 10\n",
    "output_graph = os.path.join(tmp_root_dir, \"output_graph.pb\")\n",
    "output_labels = os.path.join(tmp_root_dir, \"output_labels.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_image_lists(image_dir, testing_percentage, validation_percentage):\n",
    "    if not gfile.Exists(image_dir):\n",
    "        tf.logging.error(\"Image directory '\" + image_dir + \"' not found.\")\n",
    "        return None\n",
    "    result = collections.OrderedDict()\n",
    "    sub_dirs = [os.path.join(image_dir,item) for item in gfile.ListDirectory(image_dir)]\n",
    "    sub_dirs = sorted(item for item in sub_dirs if gfile.IsDirectory(item))\n",
    "    for sub_dir in sub_dirs:\n",
    "        extensions = ['jpg', 'jpeg', 'JPG', 'JPEG']\n",
    "        file_list = []\n",
    "        dir_name = os.path.basename(sub_dir)\n",
    "        if dir_name == image_dir:\n",
    "            continue\n",
    "        tf.logging.info(\"Looking for images in '\" + dir_name + \"'\")\n",
    "        for extension in extensions:\n",
    "            file_glob = os.path.join(image_dir, dir_name, '*.' + extension)\n",
    "            file_list.extend(gfile.Glob(file_glob))\n",
    "        if not file_list:\n",
    "            tf.logging.warning('No files found')\n",
    "            continue\n",
    "        if len(file_list) < 20:\n",
    "            tf.logging.warning('WARNING: Folder has less than 20 images, which may cause issues.')\n",
    "        elif len(file_list) > MAX_NUM_IMAGES_PER_CLASS:\n",
    "            tf.logging.warning(\n",
    "              'WARNING: Folder {} has more than {} images. Some images will '\n",
    "              'never be selected.'.format(dir_name, MAX_NUM_IMAGES_PER_CLASS))\n",
    "        label_name = re.sub(r'[^a-z0-9]+', ' ', dir_name.lower())\n",
    "        training_images = []\n",
    "        testing_images = []\n",
    "        validation_images = []\n",
    "        for file_name in file_list:\n",
    "            base_name = os.path.basename(file_name)\n",
    "            hash_name = re.sub(r'_nohash_.*$', '', file_name)\n",
    "            hash_name_hashed = hashlib.sha1(compat.as_bytes(hash_name)).hexdigest()\n",
    "            percentage_hash = ((int(hash_name_hashed, 16) % (MAX_NUM_IMAGES_PER_CLASS + 1)) * (100.0 / MAX_NUM_IMAGES_PER_CLASS))\n",
    "            if percentage_hash < validation_percentage:\n",
    "                validation_images.append(base_name)\n",
    "            elif percentage_hash < (testing_percentage + validation_percentage):\n",
    "                testing_images.append(base_name)\n",
    "            else:\n",
    "                training_images.append(base_name)\n",
    "        result[label_name] = {\n",
    "            'dir': dir_name,\n",
    "            'training': training_images,\n",
    "            'testing': testing_images,\n",
    "            'validation': validation_images,\n",
    "        }\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_jpeg_decoding(model):\n",
    "    input_height = get_model_attribute(model, \"input_height\")\n",
    "    input_width = get_model_attribute(model, \"input_width\")\n",
    "    input_depth = get_model_attribute(model, \"input_depth\")\n",
    "    input_mean = get_model_attribute(model, \"input_mean\", 0)\n",
    "    input_std = get_model_attribute(model, \"input_std\", 255)\n",
    "    \n",
    "    jpeg_data = tf.placeholder(tf.string, name='DecodeJPGInput')\n",
    "    decoded_image = tf.image.decode_jpeg(jpeg_data, channels=input_depth)\n",
    "    decoded_image_as_float = tf.cast(decoded_image, dtype=tf.float32)\n",
    "    decoded_image_4d = tf.expand_dims(decoded_image_as_float, 0)\n",
    "    resize_shape = tf.stack([input_height, input_width])\n",
    "    resize_shape_as_int = tf.cast(resize_shape, dtype=tf.int32)\n",
    "    resized_image = tf.image.resize_bilinear(decoded_image_4d,\n",
    "                                           resize_shape_as_int)\n",
    "    offset_image = tf.subtract(resized_image, input_mean)\n",
    "    mul_image = tf.multiply(offset_image, 1.0 / input_std)\n",
    "    return jpeg_data, mul_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bottleneck_path(image_lists, label_name, index, bottleneck_dir,category, architecture):\n",
    "    return get_image_path(image_lists, label_name, index, bottleneck_dir,category) + '_' + architecture + '.txt'\n",
    "\n",
    "def get_image_path(image_lists, label_name, index, image_dir, category):\n",
    "    label_lists = image_lists[label_name]\n",
    "    category_list = label_lists[category]\n",
    "    if not category_list:\n",
    "        tf.logging.fatal('Label %s has no images in the category %s.',label_name, category)\n",
    "    mod_index = index % len(category_list)\n",
    "    base_name = category_list[mod_index]\n",
    "    sub_dir = label_lists['dir']\n",
    "    full_path = os.path.join(image_dir, sub_dir, base_name)\n",
    "    return full_path\n",
    "\n",
    "def get_or_create_bottleneck(sess, image_lists, label_name, index, image_dir,\n",
    "                             category, bottleneck_dir, jpeg_data_tensor,\n",
    "                             decoded_image_tensor, resized_input_tensor,\n",
    "                             bottleneck_tensor, architecture):\n",
    "    label_lists = image_lists[label_name]\n",
    "    sub_dir = label_lists['dir']\n",
    "    sub_dir_path = os.path.join(bottleneck_dir, sub_dir)\n",
    "    ensure_dir_exists(sub_dir_path)\n",
    "    bottleneck_path = get_bottleneck_path(image_lists, label_name, index,bottleneck_dir, category, architecture)\n",
    "    if not os.path.exists(bottleneck_path):\n",
    "        try:\n",
    "            create_bottleneck_file(bottleneck_path, image_lists, label_name, index,\n",
    "                               image_dir, category, sess, jpeg_data_tensor,\n",
    "                               decoded_image_tensor, resized_input_tensor,\n",
    "                               bottleneck_tensor)\n",
    "        except:\n",
    "            return None\n",
    "    with open(bottleneck_path, 'r') as bottleneck_file:\n",
    "        bottleneck_string = bottleneck_file.read()\n",
    "    did_hit_error = False\n",
    "    try:\n",
    "        bottleneck_values = [float(x) for x in bottleneck_string.split(',')]\n",
    "    except ValueError:\n",
    "        tf.logging.warning('Invalid float found, recreating bottleneck')\n",
    "        did_hit_error = True\n",
    "    if did_hit_error:\n",
    "        create_bottleneck_file(bottleneck_path, image_lists, label_name, index,\n",
    "                           image_dir, category, sess, jpeg_data_tensor,\n",
    "                           decoded_image_tensor, resized_input_tensor,\n",
    "                           bottleneck_tensor)\n",
    "        with open(bottleneck_path, 'r') as bottleneck_file:\n",
    "            bottleneck_string = bottleneck_file.read()\n",
    "        bottleneck_values = [float(x) for x in bottleneck_string.split(',')]\n",
    "    return bottleneck_values\n",
    "\n",
    "def cache_bottlenecks(sess, image_lists, image_dir, bottleneck_dir,\n",
    "                      jpeg_data_tensor, decoded_image_tensor,\n",
    "                      resized_input_tensor, bottleneck_tensor, architecture):\n",
    "    how_many_bottlenecks = 0\n",
    "    ensure_dir_exists(bottleneck_dir)\n",
    "    for label_name, label_lists in image_lists.items():\n",
    "        for category in ['training', 'testing', 'validation']:\n",
    "            category_list = label_lists[category]\n",
    "            for index, unused_base_name in enumerate(category_list):\n",
    "                get_or_create_bottleneck(\n",
    "                    sess, image_lists, label_name, index, image_dir, category,\n",
    "                    bottleneck_dir, jpeg_data_tensor, decoded_image_tensor,\n",
    "                    resized_input_tensor, bottleneck_tensor, architecture)\n",
    "\n",
    "                how_many_bottlenecks += 1\n",
    "                if how_many_bottlenecks % 100 == 0:\n",
    "                    tf.logging.info(str(how_many_bottlenecks) + ' bottleneck files created.')\n",
    "                    \n",
    "def create_bottleneck_file(bottleneck_path, image_lists, label_name, index,image_dir, category, \n",
    "                           sess, jpeg_data_tensor,decoded_image_tensor, resized_input_tensor,bottleneck_tensor):\n",
    "    tf.logging.info('Creating bottleneck at ' + bottleneck_path)\n",
    "    image_path = get_image_path(image_lists, label_name, index,\n",
    "                              image_dir, category)\n",
    "    if not gfile.Exists(image_path):\n",
    "        tf.logging.fatal('File does not exist %s', image_path)\n",
    "    image_data = gfile.FastGFile(image_path, 'rb').read()\n",
    "    try:\n",
    "        bottleneck_values = run_bottleneck_on_image(\n",
    "            sess, image_data, jpeg_data_tensor, decoded_image_tensor,resized_input_tensor, bottleneck_tensor\n",
    "        )\n",
    "    except Exception as e:\n",
    "        raise(RuntimeError('Error during processing file {} ({})'.format(image_path, str(e))))\n",
    "    bottleneck_string = ','.join(str(x) for x in bottleneck_values)\n",
    "    with open(bottleneck_path, 'w') as bottleneck_file:\n",
    "        bottleneck_file.write(bottleneck_string)\n",
    "        \n",
    "def run_bottleneck_on_image(sess, image_data, image_data_tensor,decoded_image_tensor, \n",
    "                            resized_input_tensor,bottleneck_tensor):\n",
    "    # First decode the JPEG image, resize it, and rescale the pixel values.\n",
    "    resized_input_values = sess.run(decoded_image_tensor,{image_data_tensor: image_data})\n",
    "    # Then run it through the recognition network.\n",
    "    bottleneck_values = sess.run(bottleneck_tensor,{resized_input_tensor: resized_input_values})\n",
    "    bottleneck_values = np.squeeze(bottleneck_values)\n",
    "    return bottleneck_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_final_training_ops(model, class_count, final_tensor_name, bottleneck_tensor,bottleneck_tensor_size):\n",
    "    with tf.name_scope('input'):\n",
    "        bottleneck_input = tf.placeholder_with_default(\n",
    "            bottleneck_tensor,shape=[None, bottleneck_tensor_size],name='BottleneckInputPlaceholder'\n",
    "        )\n",
    "\n",
    "        ground_truth_input = tf.placeholder(tf.float32,[None, class_count],name='GroundTruthInput')\n",
    "\n",
    "    # Organizing the following ops as `final_training_ops` so they're easier to see in TensorBoard\n",
    "    layer_name = 'final_training_ops'\n",
    "    with tf.name_scope(layer_name):\n",
    "        with tf.name_scope('weights'):\n",
    "            initial_value = tf.truncated_normal([bottleneck_tensor_size, class_count], stddev=0.001)\n",
    "            layer_weights = tf.Variable(initial_value, name='final_weights')\n",
    "        with tf.name_scope('biases'):\n",
    "            layer_biases = tf.Variable(tf.zeros([class_count]), name='final_biases')\n",
    "        with tf.name_scope('Wx_plus_b'):\n",
    "            logits = tf.matmul(bottleneck_input, layer_weights) + layer_biases\n",
    "            tf.summary.histogram('pre_activations', logits)\n",
    "\n",
    "    final_tensor = tf.nn.softmax(logits, name=final_tensor_name)\n",
    "    tf.summary.histogram('activations', final_tensor)\n",
    "\n",
    "    with tf.name_scope('cross_entropy'):\n",
    "        cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=ground_truth_input, logits=logits)\n",
    "        with tf.name_scope('total'):\n",
    "            cross_entropy_mean = tf.reduce_mean(cross_entropy)\n",
    "    tf.summary.scalar('cross_entropy', cross_entropy_mean)\n",
    "\n",
    "    with tf.name_scope('train'):\n",
    "        learning_rate = get_model_attribute(model, \"learning_rate\", 0.01)\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "        train_step = optimizer.minimize(cross_entropy_mean)\n",
    "\n",
    "    return (train_step, cross_entropy_mean, bottleneck_input, ground_truth_input,final_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_evaluation_step(result_tensor, ground_truth_tensor):\n",
    "    with tf.name_scope('accuracy'):\n",
    "        with tf.name_scope('correct_prediction'):\n",
    "            prediction = tf.argmax(result_tensor, 1)\n",
    "            correct_prediction = tf.equal(prediction, tf.argmax(ground_truth_tensor, 1))\n",
    "        with tf.name_scope('accuracy'):\n",
    "            evaluation_step = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    tf.summary.scalar('accuracy', evaluation_step)\n",
    "    return evaluation_step, prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def get_random_cached_bottlenecks(sess, image_lists, how_many, category,\n",
    "                                  bottleneck_dir, image_dir, jpeg_data_tensor,\n",
    "                                  decoded_image_tensor, resized_input_tensor,\n",
    "                                  bottleneck_tensor, architecture):\n",
    "    class_count = len(image_lists.keys())\n",
    "    bottlenecks = []\n",
    "    ground_truths = []\n",
    "    filenames = []\n",
    "    if how_many >= 0:\n",
    "        # Retrieve a random sample of bottlenecks.\n",
    "        for unused_i in range(how_many):\n",
    "            label_index = random.randrange(class_count)\n",
    "            label_name = list(image_lists.keys())[label_index]\n",
    "            image_index = random.randrange(MAX_NUM_IMAGES_PER_CLASS + 1)\n",
    "            image_name = get_image_path(image_lists, label_name, image_index,image_dir, category)\n",
    "            bottleneck = get_or_create_bottleneck(\n",
    "              sess, image_lists, label_name, image_index, image_dir, category,\n",
    "              bottleneck_dir, jpeg_data_tensor, decoded_image_tensor,\n",
    "              resized_input_tensor, bottleneck_tensor, architecture)\n",
    "            if bottleneck is not None:\n",
    "                ground_truth = np.zeros(class_count, dtype=np.float32)\n",
    "                ground_truth[label_index] = 1.0\n",
    "                bottlenecks.append(bottleneck)\n",
    "                ground_truths.append(ground_truth)\n",
    "                filenames.append(image_name)\n",
    "    else:\n",
    "        # Retrieve all bottlenecks.\n",
    "        for label_index, label_name in enumerate(image_lists.keys()):\n",
    "            for image_index, image_name in enumerate(image_lists[label_name][category]):\n",
    "                image_name = get_image_path(image_lists, label_name, image_index,image_dir, category)\n",
    "        bottleneck = get_or_create_bottleneck(\n",
    "            sess, image_lists, label_name, image_index, image_dir, category,\n",
    "            bottleneck_dir, jpeg_data_tensor, decoded_image_tensor,\n",
    "            resized_input_tensor, bottleneck_tensor, architecture)\n",
    "        if bottleneck:\n",
    "            ground_truth = np.zeros(class_count, dtype=np.float32)\n",
    "            ground_truth[label_index] = 1.0\n",
    "            bottlenecks.append(bottleneck)\n",
    "            ground_truths.append(ground_truth)\n",
    "            filenames.append(image_name)\n",
    "    return bottlenecks, ground_truths, filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_graph_to_file(sess, graph, graph_file_name):\n",
    "    output_graph_def = graph_util.convert_variables_to_constants(sess, graph.as_graph_def(), [final_tensor_name])\n",
    "    with gfile.FastGFile(graph_file_name, 'wb') as f:\n",
    "        f.write(output_graph_def.SerializeToString())\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = models['mobilenet']\n",
    "graph = load_graph(models['mobilenet'])\n",
    "bottleneck_tensor = graph.get_tensor_by_name(get_model_attribute(model, \"bottleneck_tensor_name\") )\n",
    "resized_image_tensor = graph.get_tensor_by_name(get_model_attribute( model, \"resized_input_tensor_name\") )\n",
    "\n",
    "testing_percentage = 10\n",
    "validation_percentage = 10\n",
    "image_dir = root_dir\n",
    "image_lists = create_image_lists(image_dir,testing_percentage,validation_percentage)\n",
    "class_count = len(image_lists.keys())\n",
    "if class_count == 0:\n",
    "    print('No valid folders of images found')\n",
    "if class_count == 1:\n",
    "    print('Only one valid folder of images found - multiple classes are needed for classification.')\n",
    "    \n",
    "with tf.Session(graph=graph) as sess:\n",
    "    # Set up the image decoding sub-graph.\n",
    "    jpeg_data_tensor, decoded_image_tensor = add_jpeg_decoding(model)\n",
    "    cache_bottlenecks(sess, image_lists, image_dir,bottleneck_dir, jpeg_data_tensor,\n",
    "                    decoded_image_tensor, resized_image_tensor, bottleneck_tensor, architecture)\n",
    "    \n",
    "    # Add the new layer that we'll be training.\n",
    "    bottleneck_tensor_size = get_model_attribute(model, \"bottleneck_tensor_size\")\n",
    "    (train_step, cross_entropy, bottleneck_input, ground_truth_input,final_tensor) = add_final_training_ops(\n",
    "         model, len(image_lists.keys()), final_tensor_name, bottleneck_tensor,bottleneck_tensor_size)\n",
    "    \n",
    "    # Create the operations we need to evaluate the accuracy of our new layer.\n",
    "    evaluation_step, prediction = add_evaluation_step(final_tensor, ground_truth_input)\n",
    "    \n",
    "    # Merge all the summaries and write them out to the summaries_dir\n",
    "    merged = tf.summary.merge_all()\n",
    "    summaries_dir = tmp_root_dir + \"/retrain_logs\"\n",
    "    train_writer = tf.summary.FileWriter(summaries_dir + '/train',sess.graph)\n",
    "\n",
    "    validation_writer = tf.summary.FileWriter(summaries_dir + '/validation')\n",
    "\n",
    "    # Set up all our weights to their initial default values.\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess.run(init)\n",
    "    \n",
    "    # Run the training for as many cycles as requested on the command line.\n",
    "    for i in range(how_many_training_steps):\n",
    "        # Get a batch of input bottleneck values, either calculated fresh every\n",
    "        # time with distortions applied, or from the cache stored on disk.\n",
    "        (train_bottlenecks,train_ground_truth, _) = get_random_cached_bottlenecks(\n",
    "            sess, image_lists, train_batch_size, 'training',\n",
    "            bottleneck_dir, image_dir, jpeg_data_tensor,\n",
    "            decoded_image_tensor, resized_image_tensor, bottleneck_tensor,\n",
    "            architecture)\n",
    "      \n",
    "        # Feed the bottlenecks and ground truth into the graph, and run a training\n",
    "        # step. Capture training summaries for TensorBoard with the `merged` op.\n",
    "        train_summary, _ = sess.run(\n",
    "          [merged, train_step],\n",
    "          feed_dict={bottleneck_input: train_bottlenecks,ground_truth_input: train_ground_truth})\n",
    "        train_writer.add_summary(train_summary, i)\n",
    "\n",
    "        # Every so often, print out how well the graph is training.\n",
    "        is_last_step = (i + 1 == how_many_training_steps)\n",
    "        if (i % eval_step_interval) == 0 or is_last_step:\n",
    "            train_accuracy, cross_entropy_value = sess.run(\n",
    "                [evaluation_step, cross_entropy],\n",
    "                feed_dict={bottleneck_input: train_bottlenecks,ground_truth_input: train_ground_truth})\n",
    "            tf.logging.info('%s: Step %d: Train accuracy = %.1f%%' %(datetime.now(), i, train_accuracy * 100))\n",
    "            tf.logging.info('%s: Step %d: Cross entropy = %f' % (datetime.now(), i, cross_entropy_value))\n",
    "            validation_bottlenecks, validation_ground_truth, _ = (\n",
    "                get_random_cached_bottlenecks(\n",
    "                    sess, image_lists, validation_batch_size, 'validation',\n",
    "                    bottleneck_dir, image_dir, jpeg_data_tensor,\n",
    "                    decoded_image_tensor, resized_image_tensor, bottleneck_tensor,\n",
    "                    architecture\n",
    "                )\n",
    "            )\n",
    "            # Run a validation step and capture training summaries for TensorBoard\n",
    "            # with the `merged` op.\n",
    "            validation_summary, validation_accuracy = sess.run(\n",
    "                [merged, evaluation_step],\n",
    "                feed_dict={bottleneck_input: validation_bottlenecks,ground_truth_input: validation_ground_truth})\n",
    "            validation_writer.add_summary(validation_summary, i)\n",
    "            tf.logging.info('%s: Step %d: Validation accuracy = %.1f%% (N=%d)' %\n",
    "                        (datetime.now(), i, validation_accuracy * 100,len(validation_bottlenecks)))\n",
    "            \n",
    "    # We've completed all our training, so run a final test evaluation on\n",
    "    # some new images we haven't used before.\n",
    "    test_bottlenecks, test_ground_truth, test_filenames = (\n",
    "        get_random_cached_bottlenecks(\n",
    "            sess, image_lists, test_batch_size, 'testing',\n",
    "            bottleneck_dir, image_dir, jpeg_data_tensor,\n",
    "            decoded_image_tensor, resized_image_tensor, bottleneck_tensor,\n",
    "            architecture)\n",
    "    )\n",
    "    test_accuracy, predictions = sess.run(\n",
    "        [evaluation_step, prediction],\n",
    "        feed_dict={bottleneck_input: test_bottlenecks,ground_truth_input: test_ground_truth}\n",
    "    )\n",
    "    tf.logging.info('Final test accuracy = %.1f%% (N=%d)' % (test_accuracy * 100, len(test_bottlenecks)))\n",
    "\n",
    "    # Write out the trained graph and labels with the weights stored as constants.\n",
    "    model[\"custom_graph\"] = graph\n",
    "    model[\"custom_labels\"] = output_labels\n",
    "    save_graph_to_file(sess, graph, output_graph)\n",
    "    with gfile.FastGFile(output_labels, 'w') as f:\n",
    "        f.write('\\n'.join(image_lists.keys()) + '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PixieApp with the following screens:\n",
    "1. First Tab:\n",
    "   - Ask the user for a url to a web page\n",
    "   - Display the images with top 5 candidate classifications\n",
    "2. Second Tab:\n",
    "   - Display the model Graph Visualization\n",
    "3. Third Tab:\n",
    "   - Display the label in a PixieDust table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [],
   "source": [
    "from pixiedust.display.app import *\n",
    "\n",
    "@PixieApp\n",
    "class ScoreImageApp():\n",
    "    def setup(self):\n",
    "        self.model = self.parent_pixieapp.model\n",
    "        self.graph = self.parent_pixieapp.graph\n",
    "\n",
    "    @route()\n",
    "    def main_screen(self):\n",
    "        return \"\"\"\n",
    "<style>\n",
    "    div.outer-wrapper {\n",
    "        display: table;width:100%;height:300px;\n",
    "    }\n",
    "    div.inner-wrapper {\n",
    "        display: table-cell;vertical-align: middle;height: 100%;width: 100%;\n",
    "    }\n",
    "</style>\n",
    "<div class=\"outer-wrapper\">\n",
    "    <div class=\"inner-wrapper\">\n",
    "        <div class=\"col-sm-3\"></div>\n",
    "        <div class=\"input-group col-sm-6\">\n",
    "          <input id=\"url{{prefix}}\" type=\"text\" class=\"form-control\"\n",
    "              value=\"https://www.flickr.com/search/?text=cats\"\n",
    "              placeholder=\"Enter a url that contains images\">\n",
    "          <span class=\"input-group-btn\">\n",
    "            <button class=\"btn btn-default\" type=\"button\" pd_options=\"image_url=$val(url{{prefix}})\">Go</button>\n",
    "          </span>\n",
    "        </div>\n",
    "    </div>\n",
    "</div>        \n",
    "\"\"\"\n",
    "    \n",
    "    @route(image_url=\"*\")\n",
    "    @templateArgs\n",
    "    def do_process_url(self, image_url):\n",
    "        image_urls = get_image_urls(image_url)\n",
    "        return \"\"\"\n",
    "<div>\n",
    "{%for url in image_urls%}\n",
    "<div style=\"float: left; font-size: 9pt; text-align: center; width: 30%; margin-right: 1%; margin-bottom: 0.5em;\">\n",
    "<img src=\"{{url}}\" style=\"width: 100%\">\n",
    "<div style=\"display:inline-block\" pd_render_onload pd_options=\"score_url={{url}}\"></div>\n",
    "</div>\n",
    "{%endfor%}\n",
    "<p style=\"clear: both;\">\n",
    "</div>\n",
    "        \"\"\"\n",
    "    \n",
    "    @route(score_url=\"*\")\n",
    "    @templateArgs\n",
    "    def do_score_url(self, score_url):\n",
    "        scores_dict = score_image(self.graph, self.model, score_url)\n",
    "        return \"\"\"\n",
    "{%for model, results in scores_dict.items()%}\n",
    "<div style=\"font-weight:bold\">{{model}}</div>\n",
    "<ul style=\"text-align:left\">\n",
    "{%for label, confidence in results%}\n",
    "<li><b>{{label}}</b>: {{confidence}}</li>\n",
    "{%endfor%}\n",
    "</ul>\n",
    "{%endfor%}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the model graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@PixieApp\n",
    "class TensorGraphApp():\n",
    "    \"\"\"Visualize TensorFlow graph.\"\"\"\n",
    "    def setup(self):\n",
    "        self.graph = self.parent_pixieapp.graph\n",
    "        self.custom_graph = self.parent_pixieapp.model.get(\"custom_graph\", None)\n",
    "\n",
    "    @route()\n",
    "    @templateArgs\n",
    "    def main_screen(self):\n",
    "        strip_def = self.strip_consts(self.graph.as_graph_def())\n",
    "        code = \"\"\"\n",
    "            <script>\n",
    "              function load() {{\n",
    "                document.getElementById(\"{id}\").pbtxt = {data};\n",
    "              }}\n",
    "            </script>\n",
    "            <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n",
    "            <div style=\"height:600px\">\n",
    "              <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n",
    "            </div>\n",
    "        \"\"\".format(data=repr(str(strip_def)), id='graph'+ self.getPrefix()).replace('\"', '&quot;')\n",
    "\n",
    "        return \"\"\"\n",
    "{%if this.custom_graph%}\n",
    "<div style=\"margin-top:10px\" pd_refresh>\n",
    "    <pd_script>\n",
    "self.graph = self.custom_graph if self.graph is not self.custom_graph else self.parent_pixieapp.graph\n",
    "    </pd_script>\n",
    "    <span style=\"font-weight:bold\">Select a model to display:</span>\n",
    "    <select>\n",
    "        <option {%if this.graph!=this.custom_graph%}selected{%endif%} value=\"main\">MobileNet</option>\n",
    "        <option {%if this.graph==this.custom_graph%}selected{%endif%} value=\"custom\">Custom</options>\n",
    "    </select>\n",
    "{%endif%}\n",
    "<iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"{{code}}\"></iframe>\n",
    "\"\"\"\n",
    "\n",
    "    def strip_consts(self, graph_def, max_const_size=32):\n",
    "        \"\"\"Strip large constant values from graph_def.\"\"\"\n",
    "        strip_def = tf.GraphDef()\n",
    "        for n0 in graph_def.node:\n",
    "            n = strip_def.node.add() \n",
    "            n.MergeFrom(n0)\n",
    "            if n.op == 'Const':\n",
    "                tensor = n.attr['value'].tensor\n",
    "                size = len(tensor.tensor_content)\n",
    "                if size > max_const_size:\n",
    "                    tensor.tensor_content = \"<stripped {} bytes>\".format(size).encode(\"UTF-8\")\n",
    "        return strip_def"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searchable table for the model categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@PixieApp\n",
    "class LabelsApp():\n",
    "    def setup(self):\n",
    "        self.labels = self.parent_pixieapp.load_labels(\n",
    "            self.parent_pixieapp.model, as_json=True\n",
    "        )\n",
    "        self.current_labels = self.labels\n",
    "        self.custom_labels = None\n",
    "        if \"custom_labels\" in self.parent_pixieapp.model:\n",
    "            with open(self.parent_pixieapp.model[\"custom_labels\"]) as f:\n",
    "                content = f.readlines()\n",
    "            labels = [line.rstrip() for line in content if line != \"\"]\n",
    "            self.custom_labels = \\\n",
    "                [{\"index\": index, \"label\" : item} for index, item in zip(range(len(labels)), labels)]\n",
    "    \n",
    "    @route()\n",
    "    def main_screen(self):\n",
    "        return \"\"\"\n",
    "{%if this.custom_labels%}\n",
    "<div style=\"margin-top:10px\" pd_refresh>\n",
    "    <pd_script>\n",
    "self.current_labels = self.custom_labels if self.current_labels is not self.custom_labels else self.labels\n",
    "    </pd_script>\n",
    "    <span style=\"font-weight:bold\">Select a model to display:</span>\n",
    "    <select>\n",
    "        <option {%if this.current_labels!=this.labels%}selected{%endif%} value=\"main\">MobileNet</option>\n",
    "        <option {%if this.current_labels==this.custom_labels%}selected{%endif%} value=\"custom\">Custom</options>\n",
    "    </select>\n",
    "{%endif%}\n",
    "<div pd_render_onload pd_entity=\"current_labels\">\n",
    "    <pd_options>\n",
    "    {\n",
    "        \"table_noschema\": \"true\",\n",
    "        \"handlerId\": \"tableView\",\n",
    "        \"rowCount\": \"10000\",\n",
    "        \"noChartCache\": \"true\"\n",
    "        \n",
    "    }\n",
    "    </pd_options>\n",
    "</div>\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main ImageRecoApp inheriting from TemplateTabbedApp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [],
   "source": [
    "from pixiedust.apps.template import TemplateTabbedApp\n",
    "\n",
    "@PixieApp\n",
    "class ImageRecoApp(TemplateTabbedApp):\n",
    "    def setup(self):\n",
    "        self.apps = [\n",
    "            {\"title\": \"Score\", \"app_class\": \"ScoreImageApp\"},\n",
    "            {\"title\": \"Model\", \"app_class\": \"TensorGraphApp\"},\n",
    "            {\"title\": \"Labels\", \"app_class\": \"LabelsApp\"}\n",
    "        ]\n",
    "        self.model = models[\"mobilenet\"]\n",
    "        self.graph = self.load_graph(self.model)\n",
    "        \n",
    "app = ImageRecoApp()\n",
    "app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
